# ðŸ§ª Mini Project: Fine-tuning TinyLLaMA on Medical QA (LoRA)

This is a small hands-on project where I fine-tuned a ChatTemplate-compatible LLM using Hugging Face Transformers and LoRA, focused on medical Q&A.

## ðŸ”§ Stack
- Model: TinyLlama-1.1B-Chat-v1.0
- Dataset: medical_meadow_medqa
- Hardware: Mac mini M4 Pro
- Method: LoRA (Parameter-efficient fine-tuning)

## ðŸ“¦ Tools
- Hugging Face Transformers
- PEFT
- Trainer API
- Custom Chat prompt format

## ðŸš€ Goal
Iâ€™m transitioning from PKI technical support to AI engineering. This project is one step in that journey.

## ðŸ”— Repo
https://github.com/NemoMoNa/tinyllama-medqa-mini-project

## License

This project is licensed under the GNU General Public License v3.0 (GPL-3.0), due to the use of the [medical_meadow_medqa dataset](https://huggingface.co/datasets/medalpaca/medical_meadow_medqa), which is derived from GPL-licensed sources.

All code and model artifacts in this repo are subject to the same license.

Original dataset and source: https://github.com/jind11/MedQA
